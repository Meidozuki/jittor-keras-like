{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57dfb086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T14:20:34.720672Z",
     "start_time": "2022-05-15T14:20:31.556621Z"
    }
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from jittorKLike.utils import cAxis,silent_preload_jittor\n",
    "silent_preload_jittor()\n",
    "import jittor as jt\n",
    "from jittor import nn\n",
    "import abc\n",
    "import numpy as np\n",
    "from functools import partial,wraps\n",
    "# import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702c4f9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T14:20:54.086903Z",
     "start_time": "2022-05-15T14:20:54.081865Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricResultStorage(object):\n",
    "    def __init__(self,reduction='mean'):\n",
    "        '''\n",
    "        args:\n",
    "          reducetion: default is np.mean\n",
    "        '''\n",
    "        super().__init__()\n",
    "        allowed_reduction={\n",
    "            'mean':np.mean,\n",
    "            'sum':np.sum\n",
    "        }\n",
    "        self.reset()\n",
    "        self.reduction=allowed_reduction[str.lower(reduction)]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.results=[]\n",
    "        self.cnt=0\n",
    "        \n",
    "    def push(self,result):\n",
    "        self.results.append(result)\n",
    "        self.cnt+=1\n",
    "        \n",
    "    @property\n",
    "    def result(self):\n",
    "        return self.reduction(self.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1656ddc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T14:20:55.068963Z",
     "start_time": "2022-05-15T14:20:55.062963Z"
    }
   },
   "outputs": [],
   "source": [
    "class Metric(abc.ABC):\n",
    "    @wraps(MetricResultStorage.__init__, assigned=[],updated=['__annotations__'])\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self._results=MetricResultStorage(*args,**kwargs)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def cal_metric(self,*args,**kwargs):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def result(self):\n",
    "        return self._results.result\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self._results.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6def62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Losses(Metric):\n",
    "    def cal_metric(self,loss):\n",
    "        return np.sum(loss)\n",
    "    \n",
    "    def update_state(self,loss):\n",
    "        loss_=self.cal_metric(loss)\n",
    "        self._results.push(loss_)\n",
    "        return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "097d2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metric):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        #考虑已经转为one_hot label\n",
    "        super().__init__(*args,**kwargs)\n",
    "    \n",
    "    def _equal_to_int(self,a,b,dtype=jt.int16):\n",
    "        if a.shape != b.shape:\n",
    "            raise ValueError(\"Accuracy::equal: \"\\\n",
    "                             \"Except args to have the same shape, \"\\\n",
    "                            f'but receive {a.shape} and {b.shape}')\n",
    "        return jt.cast(jt.equal(a,b) ,dtype)\n",
    "    \n",
    "    def cal_metric(self,y_true,y_pred):\n",
    "        gt=jt.argmax(y_true,dim=cAxis)[0]\n",
    "        pred=jt.argmax(y_pred,dim=cAxis)[0]\n",
    "        acc=self._equal_to_int(gt,pred, jt.int16)\n",
    "        return jt.mean(acc)\n",
    "    \n",
    "    def update_state(self,y_true,y_pred):\n",
    "        acc=self.cal_metric(y_true,y_pred)\n",
    "        self._results.push(acc.numpy())\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55c14c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAccuracy(Accuracy):\n",
    "    def __init__(self):\n",
    "        # y非one_hot_label\n",
    "        super().__init__()\n",
    "    \n",
    "    def cal_metric(self,y_true,y_pred):\n",
    "        gt=y_true\n",
    "        pred=jt.argmax(y_pred,dim=cAxis)[0]\n",
    "        acc=self._equal_to_int(gt,pred, jt.int16)\n",
    "        return jt.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8affc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<super: <class 'A'>, <A object>>\n",
      "<super: <class 'Metric'>, <A object>>\n",
      "<super: <class 'Metric'>, <A object>>\n",
      "storage\n",
      "metric\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[__main__.A, __main__.Metric, abc.ABC, __main__.MetricResultStorage, object]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class A(Metric,MetricResultStorage):\n",
    "#     def __init__(self):\n",
    "        \n",
    "#         print(super())\n",
    "#         print(super(Metric,self))\n",
    "#         super().__init__()\n",
    "    \n",
    "\n",
    "# A()\n",
    "# A.mro()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
